**Resumen:** En un mundo cada vez más impulsado por los datos, la capacidad de un licenciado en física para manejar lenguajes de programación es crucial para satisfacer las necesidades de la industria. 
Este taller se enfoca en el análisis de datos extraídos de la NASA, utilizando técnicas de Machine Learning para descubrir patrones y correlaciones en conjuntos de datos complejos. 
Dirigido a estudiantes y docentes, el taller ofrece una perspectiva práctica sobre cómo los conocimientos en programación y análisis de datos pueden aplicarse en campos como la investigación científica, 
la ingeniería y la tecnología. A lo largo de la actividad, los participantes aprenderán a utilizar Google Colab, un entorno accesible que les permitirá cargar y preprocesar datos de manera eficiente. 
Se explorarán herramientas de Python, como Pandas, NumPy y Scikit-learn, que son ampliamente demandadas en la industria y esenciales para el análisis estadístico y la construcción de modelos predictivos. 
El taller incluirá estudios de casos reales provenientes de misiones espaciales y atmosféricas, lo que permitirá a los asistentes comprender cómo se utilizan los datos científicos para resolver problemas concretos. 
Al final de la actividad, los participantes no solo adquirirán conocimientos teóricos, sino también habilidades prácticas que fortalecerán su perfil profesional y los prepararán para enfrentar los 
desafíos actuales en el mercado laboral. La combinación de física y programación ofrece una ventaja competitiva en el ámbito laboral, ya que muchas industrias buscan profesionales con la capacidad de 
interpretar datos y extraer conclusiones significativas. Este taller busca inspirar a futuros físicos y científicos a desarrollar competencias en análisis de datos, alineando sus habilidades con las
demandas del mercado y fomentando su crecimiento profesional.

**Introducción:** 
En un contexto donde los datos impulsan el avance de la ciencia y la tecnología, se propone la realización de un taller orientado al análisis de datos climáticos y astronómicos,
este taller tiene la intención de proporcionar a estudiantes y docentes conocimientos prácticos y básicos en el análisis de datos científicos, integrando herramientas de Python y técnicas de Machine Learning. 
La tesis central es que el dominio de estas habilidades es clave para un licenciado en física, no solo para mejorar su comprensión y análisis de fenómenos físicos mediante el uso de datos, sino también para 
aumentar su competitividad en el mercado laboral actual, que demanda expertos capaces de extraer conclusiones significativas de grandes volúmenes de datos.
En un mundo basado en datos, muchos estudiantes y docentes de física carecen de habilidades avanzadas en análisis de datos, limitando su capacidad para explorar información científica compleja. Esto impide 
aprovechar al máximo las oportunidades que brindan fuentes de datos, en este caso datos climáticos y astronómicos, que aguardan una amplia gama de análisis y discusiones en nuestro tiempo.
Como antecedentes se enuncia un entorno global orientado por el análisis de datos e inteligencia artificial, esto precede una transformación total a los campos de estudios de las ciencias, para este caso 
la física. de ello que el uso de herramientas como Google Colab, junto a bibliotecas de Python (Pandas, NumPy, Scikit-learn), es cada vez más común en la industria y la academia.
Este taller tiene como objetivo implementar y enseñar el uso de herramientas de Python para cargar, procesar y analizar datos científicos de manera práctica y accesible. A través de estudios de casos reales,
los participantes desarrollarán habilidades aplicadas para enfrentar desafíos en análisis de datos, fortaleciendo así su perfil profesional y preparándose para el mercado laboral.

**Metodologia:**
La Metodología propuesta para el presente taller, se orienta hacia el carácter práctico  y aplicado, este se enfoca en el uso de herramientas 
de programación y análisis de datos para facilitar el manejo de estructuras de datos.
El desarrollo del taller estará estructurado para un total de 4 horas, en este tiempo se realizarán los siguientes procedimientos.
El primero de ellos, a modo de introducción, se estipula en la plataforma de google Colab, de esto se implementa y explica el entorno 
que se utilizará a lo largo de la jornada, esto con el objetivo de tener un entorno de trabajo sencillo sin la necesidad de instalaciones 
externas, como siguiente paso se construye la idea de limpieza y preprocesamiento de datos, etapa de gran importancia a la hora de manipular 
datos y juzgar la calidad de los datos. de esta segunda etapa se utilizaron librerías como Numpy y Pandas. La tercera etapa, de carácter procedimental, 
será la construcción y enseñanza de técnicas básicas de Machine Learning a través de Librerías como Scikit - Learn para el estudio de patrones y 
relaciones en un conjunto de datos. La última etapa estará dada por el caso de interpretabilidad de los resultados generados por los algoritmos aplicados 
en la sección anterior.
